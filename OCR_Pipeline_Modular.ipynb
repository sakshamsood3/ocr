{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCJUTU5DcQON",
        "outputId": "97976716-b3f7-4120-982a-4ad91fc1b304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 3s (1,698 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123105 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 3,343 kB of archives.\n",
            "After this operation, 15.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libarchive-dev amd64 3.4.0-2ubuntu1.2 [491 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libleptonica-dev amd64 1.79.0-1 [1,389 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libtesseract-dev amd64 4.1.1-2build2 [1,463 kB]\n",
            "Fetched 3,343 kB in 3s (1,281 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 123152 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.4.0-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\n",
            "Selecting previously unselected package libleptonica-dev:amd64.\n",
            "Preparing to unpack .../libleptonica-dev_1.79.0-1_amd64.deb ...\n",
            "Unpacking libleptonica-dev:amd64 (1.79.0-1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2build2) ...\n",
            "Setting up libleptonica-dev:amd64 (1.79.0-1) ...\n",
            "Setting up libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW8tjnaTcjzn",
        "outputId": "2328dcf5-d6ee-4b0d-85a0-ae8f170c9ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import csv\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def process_bill_image(image_path):\n",
        "    # Read the bill image and extract text\n",
        "    image = cv2.imread(image_path, 0)\n",
        "    text = pytesseract.image_to_string(image).lower()\n",
        "    print(text)\n",
        "\n",
        "    # Identify the date using regex\n",
        "    match = re.findall(r\"\\b(\\d{2}/\\d{2}/\\d{4})\\b\", text)\n",
        "    st = \" \".join(match)\n",
        "    print(st)\n",
        "\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "\n",
        "    #lets try to extract title\n",
        "    sent_tokens=nltk.sent_tokenize(text)\n",
        "    #print(sent_tokens)\n",
        "    org=sent_tokens[0].splitlines()[0]\n",
        "    org\n",
        "\n",
        "      #lets find the price of the category.\n",
        "    price = re.findall(r'(?:(?<=\\€)|(?<=\\$)|(?<=Rs\\.)|(?<=\\btotal\\b)|(?<=\\btotal amt : \\b)|(?<=\\bamount\\b)|(?<=\\bamt\\b))\\s*(\\d+(?:\\.\\d{1,2})?)', text)\n",
        "    price = list(map(float,price))\n",
        "    print(max(price))\n",
        "    x=max(price)\n",
        "\n",
        "    #till here we have extracted date,title and amount.\n",
        "#now its time to categorise bill whether it is shopping or grocery like wise\n",
        "#so i will first tokenise the text and search for key words\n",
        "    print(word_tokenize(text))\n",
        "\n",
        "    #we will remove punctuation\n",
        "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "    new_words = tokenizer.tokenize(text)\n",
        "    print(new_words)\n",
        "\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "\n",
        "#there are stop words like a ,an,the etc which are not required\n",
        "#so we need to filter them\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "    #there is the filetred list\n",
        "    filtered_list=[w for w in new_words if w not in stop_words ]\n",
        "    print(filtered_list)\n",
        "\n",
        "    def check_word_in_file(word, file_path):\n",
        "      with open(file_path, 'r') as file:\n",
        "          content = file.read()\n",
        "          words = [w.strip(\"'\\\"\") for w in re.split(r\"[\\\"']\\s*,\\s*[\\\"']\", content)]\n",
        "          if word in words:\n",
        "              return True\n",
        "          else:\n",
        "              return False\n",
        "   #here we will check that the bill belongs to which category\n",
        "#we will make that category true.\n",
        "    e=False\n",
        "    f=False\n",
        "    g=False\n",
        "    s=False\n",
        "    t=False\n",
        "    h=False\n",
        "    for word in filtered_list:\n",
        "        if check_word_in_file(word,'entertainment.txt'):\n",
        "            e=True\n",
        "            break\n",
        "        elif check_word_in_file(word,'food.txt'):\n",
        "            f=True\n",
        "            break\n",
        "        elif check_word_in_file(word,'grocery.txt'):\n",
        "            g=True\n",
        "            break\n",
        "        elif check_word_in_file(word,'shopping.txt'):\n",
        "            s=True\n",
        "            break\n",
        "        elif check_word_in_file(word,'travel.txt'):\n",
        "            t=True\n",
        "            break\n",
        "        elif check_word_in_file(word,'home_utility.txt'):\n",
        "            h=True\n",
        "            break\n",
        "\n",
        "\n",
        "    #question 2\n",
        "#this code the category in which the bill belongs to\n",
        "#if e is true then entertainment categrory and we will ,ake filename as entertainment.csv using\n",
        "#formatting\n",
        "    category = ''\n",
        "    filename = ''\n",
        "    if e:\n",
        "        print(\"Entertainment category\")\n",
        "        category = 'entertainment'\n",
        "        filename = 'entertainment.csv'\n",
        "    elif f:\n",
        "        print(\"Food category\")\n",
        "        category = 'food'\n",
        "        filename = 'food.csv'\n",
        "    elif s:\n",
        "        print(\"Shopping category\")\n",
        "        category = 'shopping'\n",
        "        filename = 'shopping.csv'\n",
        "    elif g:\n",
        "        print(\"Grocery category\")\n",
        "        category = 'grocery'\n",
        "        filename = 'grocery.csv'\n",
        "    elif t:\n",
        "        print(\"Transport category\")\n",
        "        category = 'transport'\n",
        "        filename = 'transport.csv'\n",
        "    elif h:\n",
        "        print(\"Home utility category\")\n",
        "        category = 'home'\n",
        "        filename = 'home.csv'\n",
        "    else:\n",
        "        print(\"Miscellaneous\")\n",
        "        category = 'miscellaneous'\n",
        "        filename = 'others.csv'\n",
        "\n",
        "    # Write the date, organization, and amount into the corresponding category CSV file\n",
        "    row_contents = [st, org, x]\n",
        "    with open(filename, 'a', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(row_contents)\n",
        "\n",
        "\n",
        "\n",
        "# Call the function with the bill image path\n",
        "bill_image_path = 'a2.png'\n",
        "process_bill_image(bill_image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ktoXnRcTnd",
        "outputId": "41d3d791-7268-4411-c014-7f1f27426afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "volachery\n",
            "chennat\n",
            "land! ine :044-68650 102\n",
            "emai ‘istcare@iststep.com\n",
            "pincode :800042\n",
            "gst number : sbaaectz295p 176\n",
            "\n",
            "retail invoice\n",
            "\n",
            "| original\n",
            "\n",
            "place of supply: tamil nadu @ 33\n",
            "\n",
            "bill no:pm6820  0t:16/11/2019 09:25 pm\n",
            "cashier id :letstepmal |\n",
            "\n",
            "customername : joseph\n",
            "\n",
            "mobile number :8985054968\n",
            "\n",
            "product name hsn coda\n",
            "qty mrps taxx disck amount\n",
            "sm baby children shampoo 33051090(18)\n",
            "1.00 192.00 gst1i8 0.00 192.00\n",
            "\n",
            "sm baby cleansing bar 10 34011190\n",
            "1.00 268,00 gst16 0.00 265.00\n",
            "him gentle baby soap 100 3401( 18)\n",
            "1.00 55.00 6sti8 0.00 55.00\n",
            "amount : 512.00\n",
            "\n",
            "discount : 0.00\n",
            "\n",
            "rod : 0.00\n",
            "\n",
            "total amt : 512.00\n",
            "\n",
            "oe re a et ee ee\n",
            "\n",
            "total savings :0.00\n",
            "tot prod/qty :3/3\n",
            "\n",
            "tax breakup :\n",
            "\n",
            "ea a pee a te hh ss ya ae mee eee st sate te se te stn me ar\n",
            "\n",
            "gst18 39.05 39.05 78.10\n",
            "\n",
            "sa! esman: roshan\n",
            "payment details :\n",
            "\n",
            "gv 250.00\n",
            "2500927\n",
            "creditcard 262 .00\n",
            "\n",
            "auth. codaxx«4803\n",
            "\n",
            "no exchange no return during sale\n",
            "no exchange on toys samp; inners\n",
            "exchange within 3 days\n",
            "\n",
            "thank you\n",
            "signature\n",
            "\f\n",
            "16/11/2019\n",
            "512.0\n",
            "['volachery', 'chennat', 'land', '!', 'ine', ':044-68650', '102', 'emai', '‘', 'istcare', '@', 'iststep.com', 'pincode', ':800042', 'gst', 'number', ':', 'sbaaectz295p', '176', 'retail', 'invoice', '|', 'original', 'place', 'of', 'supply', ':', 'tamil', 'nadu', '@', '33', 'bill', 'no', ':', 'pm6820', '0t:16/11/2019', '09:25', 'pm', 'cashier', 'id', ':', 'letstepmal', '|', 'customername', ':', 'joseph', 'mobile', 'number', ':8985054968', 'product', 'name', 'hsn', 'coda', 'qty', 'mrps', 'taxx', 'disck', 'amount', 'sm', 'baby', 'children', 'shampoo', '33051090', '(', '18', ')', '1.00', '192.00', 'gst1i8', '0.00', '192.00', 'sm', 'baby', 'cleansing', 'bar', '10', '34011190', '1.00', '268,00', 'gst16', '0.00', '265.00', 'him', 'gentle', 'baby', 'soap', '100', '3401', '(', '18', ')', '1.00', '55.00', '6sti8', '0.00', '55.00', 'amount', ':', '512.00', 'discount', ':', '0.00', 'rod', ':', '0.00', 'total', 'amt', ':', '512.00', 'oe', 're', 'a', 'et', 'ee', 'ee', 'total', 'savings', ':0.00', 'tot', 'prod/qty', ':3/3', 'tax', 'breakup', ':', 'ea', 'a', 'pee', 'a', 'te', 'hh', 'ss', 'ya', 'ae', 'mee', 'eee', 'st', 'sate', 'te', 'se', 'te', 'stn', 'me', 'ar', 'gst18', '39.05', '39.05', '78.10', 'sa', '!', 'esman', ':', 'roshan', 'payment', 'details', ':', 'gv', '250.00', '2500927', 'creditcard', '262', '.00', 'auth', '.', 'codaxx', '«', '4803', 'no', 'exchange', 'no', 'return', 'during', 'sale', 'no', 'exchange', 'on', 'toys', 'samp', ';', 'inners', 'exchange', 'within', '3', 'days', 'thank', 'you', 'signature']\n",
            "['volachery', 'chennat', 'land', 'ine', '044', '68650', '102', 'emai', 'istcare', 'iststep', 'com', 'pincode', '800042', 'gst', 'number', 'sbaaectz295p', '176', 'retail', 'invoice', 'original', 'place', 'of', 'supply', 'tamil', 'nadu', '33', 'bill', 'no', 'pm6820', '0t', '16', '11', '2019', '09', '25', 'pm', 'cashier', 'id', 'letstepmal', 'customername', 'joseph', 'mobile', 'number', '8985054968', 'product', 'name', 'hsn', 'coda', 'qty', 'mrps', 'taxx', 'disck', 'amount', 'sm', 'baby', 'children', 'shampoo', '33051090', '18', '1', '00', '192', '00', 'gst1i8', '0', '00', '192', '00', 'sm', 'baby', 'cleansing', 'bar', '10', '34011190', '1', '00', '268', '00', 'gst16', '0', '00', '265', '00', 'him', 'gentle', 'baby', 'soap', '100', '3401', '18', '1', '00', '55', '00', '6sti8', '0', '00', '55', '00', 'amount', '512', '00', 'discount', '0', '00', 'rod', '0', '00', 'total', 'amt', '512', '00', 'oe', 're', 'a', 'et', 'ee', 'ee', 'total', 'savings', '0', '00', 'tot', 'prod', 'qty', '3', '3', 'tax', 'breakup', 'ea', 'a', 'pee', 'a', 'te', 'hh', 'ss', 'ya', 'ae', 'mee', 'eee', 'st', 'sate', 'te', 'se', 'te', 'stn', 'me', 'ar', 'gst18', '39', '05', '39', '05', '78', '10', 'sa', 'esman', 'roshan', 'payment', 'details', 'gv', '250', '00', '2500927', 'creditcard', '262', '00', 'auth', 'codaxx', '4803', 'no', 'exchange', 'no', 'return', 'during', 'sale', 'no', 'exchange', 'on', 'toys', 'samp', 'inners', 'exchange', 'within', '3', 'days', 'thank', 'you', 'signature']\n",
            "['volachery', 'chennat', 'land', 'ine', '044', '68650', '102', 'emai', 'istcare', 'iststep', 'com', 'pincode', '800042', 'gst', 'number', 'sbaaectz295p', '176', 'retail', 'invoice', 'original', 'place', 'supply', 'tamil', 'nadu', '33', 'bill', 'pm6820', '0t', '16', '11', '2019', '09', '25', 'pm', 'cashier', 'id', 'letstepmal', 'customername', 'joseph', 'mobile', 'number', '8985054968', 'product', 'name', 'hsn', 'coda', 'qty', 'mrps', 'taxx', 'disck', 'amount', 'sm', 'baby', 'children', 'shampoo', '33051090', '18', '1', '00', '192', '00', 'gst1i8', '0', '00', '192', '00', 'sm', 'baby', 'cleansing', 'bar', '10', '34011190', '1', '00', '268', '00', 'gst16', '0', '00', '265', '00', 'gentle', 'baby', 'soap', '100', '3401', '18', '1', '00', '55', '00', '6sti8', '0', '00', '55', '00', 'amount', '512', '00', 'discount', '0', '00', 'rod', '0', '00', 'total', 'amt', '512', '00', 'oe', 'et', 'ee', 'ee', 'total', 'savings', '0', '00', 'tot', 'prod', 'qty', '3', '3', 'tax', 'breakup', 'ea', 'pee', 'te', 'hh', 'ss', 'ya', 'ae', 'mee', 'eee', 'st', 'sate', 'te', 'se', 'te', 'stn', 'ar', 'gst18', '39', '05', '39', '05', '78', '10', 'sa', 'esman', 'roshan', 'payment', 'details', 'gv', '250', '00', '2500927', 'creditcard', '262', '00', 'auth', 'codaxx', '4803', 'exchange', 'return', 'sale', 'exchange', 'toys', 'samp', 'inners', 'exchange', 'within', '3', 'days', 'thank', 'signature']\n",
            "Home utility category\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the categories and their corresponding file names\n",
        "categories = {\n",
        "    'entertainment': 'entertainment.txt',\n",
        "    'food': 'food.txt',\n",
        "    'grocery': 'grocery.txt',\n",
        "    'shopping': 'shopping.txt',\n",
        "    'travel': 'travel.txt',\n",
        "    'home_utility': 'home_utility.txt'\n",
        "}\n",
        "\n",
        "# Read the training data from the category files\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for category, filename in categories.items():\n",
        "    with open(filename, 'r') as file:\n",
        "        words = file.read().splitlines()\n",
        "        train_texts += words\n",
        "        train_labels += [category] * len(words)\n",
        "\n",
        "# Train a machine learning model\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "y_train = train_labels\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Classify the input words\n",
        "input_words = filtered_list  # Replace with your input words\n",
        "X_test = vectorizer.transform(input_words)\n",
        "predicted_labels = model.predict(X_test)\n",
        "\n",
        "# Determine the most frequent predicted label\n",
        "predicted_category = max(set(predicted_labels), key=predicted_labels.count)\n",
        "filename = f'{predicted_category}.csv'\n",
        "\n",
        "print(f\"{predicted_category.capitalize()} category\")\n",
        "\n",
        "# Write the date, organization, and amount into the corresponding category CSV file\n",
        "row_contents = [st, org, x]\n",
        "with open(filename, 'a', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(row_contents)\n"
      ],
      "metadata": {
        "id": "7YIoLUR2fKx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}